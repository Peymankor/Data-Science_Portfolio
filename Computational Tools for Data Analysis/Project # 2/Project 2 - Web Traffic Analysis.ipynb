{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Project 2 - Web Traffic Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjQLn2d2PChT",
        "colab_type": "text"
      },
      "source": [
        "# Project 2: Web Traffic Analysis\n",
        "**This is the second of three mandatory projects to be handed in as part of the assessment for the course 02807 Computational Tools for Data Science at Technical University of Denmark, autumn 2019.**\n",
        "\n",
        "#### Practical info\n",
        "- **The project is to be done in groups of at most 3 students**\n",
        "- **Each group has to hand in _one_ Jupyter notebook (this notebook) with their solution**\n",
        "- **The hand-in of the notebook is due 2019-11-10, 23:59 on DTU Inside**\n",
        "\n",
        "#### Your solution\n",
        "- **Your solution should be in Python**\n",
        "- **For each question you may use as many cells for your solution as you like**\n",
        "- **You should document your solution and explain the choices you've made (for example by using multiple cells and use Markdown to assist the reader of the notebook)**\n",
        "- **You should not remove the problem statements**\n",
        "- **Your notebook should be runnable, i.e., clicking [>>] in Jupyter should generate the result that you want to be assessed**\n",
        "- **You are not expected to use machine learning to solve any of the exercises**\n",
        "- **You will be assessed according to correctness and readability of your code, choice of solution, choice of tools and libraries, and documentation of your solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoAGrh9hPChc",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "In this project your task is to analyze a stream of log entries. A log entry consists of an [IP address](https://en.wikipedia.org/wiki/IP_address) and a [domain name](https://en.wikipedia.org/wiki/Domain_name). For example, a log line may look as follows:\n",
        "\n",
        "`192.168.0.1 somedomain.dk`\n",
        "\n",
        "One log line is the result of the event that the domain name was visited by someone having the corresponding IP address. Your task is to analyze the traffic on a number of domains. Counting the number of unique IPs seen on a domain doesn't correspond to the exact number of unique visitors, but it is a good estimate.\n",
        "\n",
        "Specifically, you should answer the following questions from the stream of log entries.\n",
        "\n",
        "- How many unique IPs are there in the stream?\n",
        "- How many unique IPs are there for each domain?\n",
        "- How many times was IP X seen on domain Y? (for some X and Y provided at run time)\n",
        "\n",
        "**The answers to these questions can be approximate!**\n",
        "\n",
        "You should also try to answer one or more of the following, more advanced, questions. The answers to these should also be approximate.\n",
        "\n",
        "- How many unique IPs are there for the domains $d_1, d_2, \\ldots$?\n",
        "- How many times was IP X seen on domains $d_1, d_2, \\ldots$?\n",
        "- What are the X most frequent IPs in the stream?\n",
        "\n",
        "You should use algorithms and data structures that you've learned about in the lectures, and you should provide your own implementations of these.\n",
        "\n",
        "Furthermore, you are expected to:\n",
        "\n",
        "- Document the accuracy of your answers when using algorithms that give approximate answers\n",
        "- Argue why you are using certain parameters for your data structures\n",
        "\n",
        "This notebook is in three parts. In the first part you are given an example of how to read from the stream (which for the purpose of this project is a remote file). In the second part you should implement the algorithms and data structures that you intend to use, and in the last part you should use these for analyzing the stream."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PksQWOV3PChg",
        "colab_type": "text"
      },
      "source": [
        "## Reading the stream\n",
        "The following code reads a remote file line by line. It is wrapped in a generator to make it easier to extend. You may modify this if you want to, but your solution should remain parametrized, so that your notebook can be run without having to consume the entire file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT5w661qPChj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib\n",
        "\n",
        "def stream(n):\n",
        "    i = 0\n",
        "    with urllib.request.urlopen('https://files.dtu.dk/fss/public/link/public/stream/read/traffic_2?linkToken=_DcyO-U3MjjuNzI-&itemName=traffic_2') as f:\n",
        "        for line in f:\n",
        "            element = line.rstrip().decode(\"utf-8\")\n",
        "            yield element\n",
        "            i += 1\n",
        "            if i == n:\n",
        "                break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ8DJtiUPCiF",
        "colab_type": "text"
      },
      "source": [
        "### Hash Function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To7bRLRPPCiI",
        "colab_type": "code",
        "outputId": "80b1e163-f5e3-4eba-c85b-cbb1df1cad30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install mmh3\n",
        "import mmh3"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mmh3 in /usr/local/lib/python3.6/dist-packages (2.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA3D8P41PCil",
        "colab_type": "text"
      },
      "source": [
        "### Ends Here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs49D1e9loec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvpf2Ru16MGk",
        "colab_type": "text"
      },
      "source": [
        "# QUESTION ONE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K20U6k-9tICp",
        "colab_type": "text"
      },
      "source": [
        "## How many unique IPs are there in the stream?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWwfSjPK4oGL",
        "colab_type": "text"
      },
      "source": [
        "Now first we define the function for estimating the cardinality. to do that we use the HyperLogLog data sketch method. The main idea of the and the parameters were drawn from the orinial paper of the HyperLogLog :\n",
        "\n",
        "HyperLogLog: the analysis of a near-optimal cardinality estimation algorithm\n",
        "Philippe Flajolet, Éric Fusy, Olivier Gandouet, Frédéric Meunier\n",
        "\n",
        "\n",
        "The following open sources as well was used to make the alghorithem:\n",
        "\n",
        "\n",
        "cardinality estimation algorithm\n",
        "Philippe Flajolet, Éric Fusy, Olivier Gandouet, Frédéric Meunier\n",
        "\n",
        "The following open sources as well was used to make the alghorithem:\n",
        "\n",
        "hyperloglog, HLL (both available in pipy.org)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLIcxy_iIwJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import struct, copy\n",
        "import numpy as np\n",
        "import warnings\n",
        "import hashlib\n",
        "\n",
        "\n",
        "def sha1_hash32(data):\n",
        "   \n",
        "    return struct.unpack('<I', hashlib.sha1(data).digest()[:4])[0]\n",
        "\n",
        "\n",
        "_bit_length = lambda bits : bits.bit_length()\n",
        "\n",
        "\n",
        "class HyperLogLog_webt(object):\n",
        "    \n",
        "    __slots__ = ('p', 'm', 'reg', 'alpha', 'max_rank', 'hashfunc')\n",
        "    \n",
        "    _hash_range_bit = 32\n",
        "    _hash_range_byte = 4\n",
        "\n",
        "    def _get_alpha(self, p):\n",
        "        return 0.7213 / (1.0 + 1.079 / (1 << p))\n",
        "\n",
        "    def __init__(self, p=8, reg=None, hashfunc=sha1_hash32, hashobj=None):\n",
        "        if reg is None:\n",
        "            self.p = p\n",
        "            self.m = 1 << p\n",
        "            self.reg = np.zeros((self.m,), dtype=np.int8)\n",
        "        self.hashfunc = hashfunc\n",
        "        self.alpha = self._get_alpha(self.p)\n",
        "        self.max_rank = self._hash_range_bit - self.p\n",
        "\n",
        "    def update(self, b):\n",
        "        \n",
        "        hv = self.hashfunc(b)\n",
        "        reg_index = hv & (self.m - 1)\n",
        "        bits = hv >> self.p\n",
        "        self.reg[reg_index] = max(self.reg[reg_index], self._get_rank(bits))\n",
        "\n",
        "    def count(self):\n",
        "        \n",
        "        e = self.alpha * float(self.m ** 2) / np.sum(2.0**(-self.reg))\n",
        "        small_range_threshold = (5.0 / 2.0) * self.m\n",
        "        \n",
        "        if e <= small_range_threshold:\n",
        "            num_zero = self.m - np.count_nonzero(self.reg)\n",
        "            return self._linearcounting(num_zero)\n",
        "        if e <= (1.0 / 30.0) * (1 << 32):\n",
        "            return e\n",
        "        return self._largerange_correction(e)\n",
        "    def _get_rank(self, bits):\n",
        "        rank = self.max_rank - _bit_length(bits) + 1\n",
        "        return rank\n",
        "    def _linearcounting(self, num_zero):\n",
        "        return self.m * np.log(self.m / float(num_zero))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqkxeNVl9WCI",
        "colab_type": "code",
        "outputId": "73518657-0e4e-4aa9-a1c6-118327f9b5b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "1 << 8"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL6mg1a434E7",
        "colab_type": "text"
      },
      "source": [
        "Let's have a small test on the function, we build a list containing the 6 unique names adding two repeatative names and compare the the function response with the real number of unique component of the list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQDYvWFP21Lk",
        "colab_type": "code",
        "outputId": "b5fa047a-ae5b-460f-b29d-5372078d9a47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "Prof_TA = ['Philip Bille', 'Patrick Hagge Cording', 'Inge Li Gørtz', 'Inge Li Gørtz',\n",
        "'Bastian Ellegård Grønager', 'Max Harry Rishøj Pedersen', 'Sarah Alexandra Maria Van Dam','Sarah Alexandra Maria Van Dam' ]\n",
        "\n",
        "h = HyperLogLog_webt()\n",
        "for d in Prof_TA:\n",
        "  h.update(d.encode('utf8'))\n",
        "print(\"Estimated cardinality is\", h.count())\n",
        "s1 = set(Prof_TA)\n",
        "print(\"Actual cardinality is\", len(s1))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimated cardinality is 6.0714308140329125\n",
            "Actual cardinality is 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vuRLPm555-y",
        "colab_type": "text"
      },
      "source": [
        "Now, with the Hyperloglog_webt we could analyze the cardinality of the web stream:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywj5eaUzIzNR",
        "colab_type": "code",
        "outputId": "97d0648f-ecf3-485c-b2bd-5d41770b9d37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "STREAM_SIZE = 10000\n",
        "web_traffic_stream = stream(STREAM_SIZE)\n",
        "##\n",
        "h = HyperLogLog_webt()\n",
        "listsave =[]\n",
        "for l in web_traffic_stream:\n",
        "    ip = re.findall( r'[0-9]+(?:\\.[0-9]+){3}', l)[0]\n",
        "    listsave.append(ip)\n",
        "    h.update(ip.encode('utf8'))\n",
        "print(\"Estimated cardinality is\", h.count())\n",
        "s1 = set(listsave)\n",
        "print(\"Actual cardinality is\", len(s1))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimated cardinality is 9482.081530493413\n",
            "Actual cardinality is 9985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5kZZmcV9bgZ",
        "colab_type": "text"
      },
      "source": [
        "It must be noted that the error of the algorithm is typical (based on paper):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drLPi4T29pRA",
        "colab_type": "text"
      },
      "source": [
        "Expected_Value +- (1.04/sqrt(m))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8lFM9sv91Fb",
        "colab_type": "code",
        "outputId": "cb8382c9-68c2-4593-bd1f-f5ceb8b7bd3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "relative_error = 1.04/(1 << 8)**0.5\n",
        "relative_error"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.065"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_ImVXBO6bAG",
        "colab_type": "text"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFW5-iBg458z",
        "colab_type": "text"
      },
      "source": [
        "# QUESTION TWO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7MZAAWRAyD5",
        "colab_type": "text"
      },
      "source": [
        "##How many unique IPs are there for each domain?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3ij1YuBEyVc",
        "colab_type": "text"
      },
      "source": [
        "For answer this question, we will use the FM Sketch algoritm https://www.cs.helsinki.fi/u/jilu/paper/FMSketch.pdf \n",
        "This will help us to approximate the number of distinct elements in a\n",
        "stream with a single pass and space efficient.\n",
        "\n",
        "We will define the size of the domain of our hash function HASH_DOMAIN_SIZE, that is the total different hashes values that we can get from applying the hash function\n",
        "\n",
        "For purposes of providing examples and quick overviews, we will use in some cases fix size of streaming. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcJCL7VwEant",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string_hash(word,n, seed):\n",
        "  return sum(ord(char) for char in word)%n\n",
        "  return mmh3.hash(word,seed)%n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSWLB3sdwkr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trailing_zeros(longint):\n",
        "    manipulandum = str(longint)\n",
        "    return len(manipulandum)-len(manipulandum.rstrip('0'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXt-CaBzwnD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function that returns the position of the first zero in an array\n",
        "def first_zero(array):\n",
        "    for i, value in enumerate(array):\n",
        "        if value==0:\n",
        "            return i\n",
        "    return len(array)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n18DkSwrwno_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HASH_DOMAIN_SIZE=100\n",
        "\n",
        "\n",
        "def FM_sketch(stream):\n",
        "    #We iterate for every URL\n",
        "    #We create a dictionary for saving every URL we find\n",
        "    dict_webs = {}  \n",
        "    for l in stream:\n",
        "        #We get the ip form the string\n",
        "        ip=re.findall( r'[0-9]+(?:\\.[0-9]+){3}', l )\n",
        "        if(len(ip)>=1):\n",
        "            #First we check if the current URL is in the dictonary\n",
        "            url=l.split()[1]\n",
        "            if url not in dict_webs:\n",
        "                #We initialize the FM array\n",
        "                FM_array = [0] * HASH_DOMAIN_SIZE\n",
        "                dict_webs[url]=FM_array\n",
        "            #We retrieve the array from the dictionary\n",
        "            FM_array=dict_webs[url]\n",
        "            #We transform the hashed ip to binary, and then we get the tail of the binary value\n",
        "            FM_array[trailing_zeros(bin(string_hash(ip[0],HASH_DOMAIN_SIZE, 41)))]=1\n",
        "            #We save the updated FM_array in the dictionary\n",
        "            dict_webs[url]=FM_array\n",
        "    dict_webs_count={}\n",
        "    #We last compute the estimated value\n",
        "    for url in dict_webs.keys():\n",
        "        FM_array=dict_webs[url]\n",
        "        #Where 0.77351 is the correlation factor\n",
        "        dict_webs_count[url]=2**first_zero(FM_array)/ 0.77351\n",
        "    return dict_webs_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw5WDYpgSorp",
        "colab_type": "text"
      },
      "source": [
        "### This give us a dictionary with the different URL and the estimated number of unique IPs. This is an aproximate solution, because we are based on statistical estimation approximating computation with a smaller space with logarithmic complexity in the number of distinct elements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xlr19Oq9l4b0",
        "colab_type": "code",
        "outputId": "24982653-e1cf-4192-efa8-3e5341c6e844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "my_stream=stream(1000)\n",
        "\n",
        "\n",
        "FM_sketch(my_stream)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'databricks.com': 20.6849297358793,\n",
              " 'datarobot.com': 2.5856162169849126,\n",
              " 'dtu.dk': 82.7397189435172,\n",
              " 'github.com': 41.3698594717586,\n",
              " 'google.com': 20.6849297358793,\n",
              " 'pandas.pydata.org': 82.7397189435172,\n",
              " 'python.org': 165.4794378870344,\n",
              " 'spark.apache.org': 5.171232433969825,\n",
              " 'wikipedia.org': 165.4794378870344}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttgIk0vV5Bwb",
        "colab_type": "text"
      },
      "source": [
        "# QUESTION THREE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX9y7I3_lzzf",
        "colab_type": "text"
      },
      "source": [
        "##How many times was IP X seen on domain Y? (for some X and Y provided at run time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbGVJC6oZdqq",
        "colab_type": "text"
      },
      "source": [
        "### Here we seek the number of times a given IP address appears on a particular domain. \n",
        "### A number of hash functions are created. Subsequently, a dictionary is also created in order to generate keys that will be hashed. \n",
        "\n",
        "### We increase the value of every hash in its corresponding matrix. First we check if the current URL is in the dictonary, if it is, we will use the current matrix, if not, we create a new one and so on.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0je7EXSnPT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import mmh3\n",
        "import numpy as np\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wELT4KrOlAB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STREAM_SIZE = 10000\n",
        "customer_stream = stream(STREAM_SIZE) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50cHw9HdJ_p1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hash1(string):\n",
        "  return string_hash(string,100, 1)\n",
        "def hash2(string):\n",
        "  return string_hash(string, 100, 12) \n",
        "def hash3(string):\n",
        "  return string_hash(string, 100, 23) \n",
        "def hash4(string):\n",
        "  return string_hash(string, 100, 34) \n",
        "def hash5(string):\n",
        "  return string_hash(string,100, 40)\n",
        "def hash6(string):\n",
        "  return string_hash(string, 100, 50) \n",
        "def hash7(string):\n",
        "  return string_hash(string, 100, 60) \n",
        "def hash8(string):\n",
        "  return string_hash(string, 100, 77) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWZYdVFZeLtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "HASH_DOMAIN_SIZE=1000 #max number of rows\n",
        "\n",
        "def countMin_sketch(hashes, stream):\n",
        "  #We create the matrix and set its values to 0\n",
        "  \n",
        "  #We create a dictionary for saving every URL we find\n",
        "  dict_webs = {}  \n",
        "  for l in stream:\n",
        "    for indx,hash in enumerate(hashes):\n",
        "      #We get the ip form the string\n",
        "      ip=re.findall( r'[0-9]+(?:\\.[0-9]+){3}', l )\n",
        "      if(len(ip)>=1):\n",
        "        #We increase the value of every hash in its corresponding matrix\n",
        "        #First we check if the current URL is in the dictonary, if it is, we will use the current matrix, if not, we create a new one\n",
        "        url=l.split()[1]\n",
        "        if url in dict_webs:\n",
        "            #We update the Matrix\n",
        "            M=dict_webs[url]\n",
        "            M[indx][hash(ip[0])]=M[indx][hash(ip[0])]+1\n",
        "            dict_webs[url]=M\n",
        "        else:\n",
        "            #We create a new Matrix\n",
        "            M = np.zeros((len(hashes), HASH_DOMAIN_SIZE))\n",
        "            M[indx][hash(ip[0])]=M[indx][hash(ip[0])]+1\n",
        "            dict_webs[url]=M\n",
        "  return dict_webs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHTbdN49FICT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hashes = [hash1, hash2, hash3, hash4,hash5, hash6, hash7, hash8]\n",
        "my_stream=stream(500)\n",
        "\n",
        "M=countMin_sketch(hashes, my_stream)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yksuRUsgWFjT",
        "colab_type": "text"
      },
      "source": [
        "###Let's consider an instance to test our function. We have manually inserted a domain, that is domain Y and IP X to test our function. The result is impressive  for a given fixed data, the number of times the given IP address visited a given domain is very accurate in this test results. Through this, our function can process a data stream. \n",
        "\n",
        "### Equally, important, it is found that when the number of hashes increases, the accuracy of the function improves greatly. However, it must be stressed that there is a trade-off between accuracy and space usage. This means, we are sacrificing space for accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgBzfH-wGEe_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d10a747-4c9a-4e6d-d62a-52346bd95f71"
      },
      "source": [
        "def count_ip(url, ip):\n",
        "  array=[]\n",
        "  for index,hash in enumerate(hashes):\n",
        "    array.append(M[url][index][hash(ip)])\n",
        "  return min(array)\n",
        "\n",
        "count_ip('python.org', \"203.85.185.49\")\n",
        "\n",
        "#https://florian.github.io/count-min-sketch/\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEs1yXkuWspI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn6jG0K7VAH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}