{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Members:\n",
    "* Sergio Hernandez Lopez\n",
    "* Peyman Kor\n",
    "* Emmanuel Obeng-Ankoana Yaafi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_9cn4gs5I82K"
   },
   "source": [
    "# Part 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-p5nRwgC6ml"
   },
   "source": [
    "[transactions.csv](https://raw.githubusercontent.com/patrickcording/02807-comp-tools/master/docker/work/data/transactions.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lIRR3Mn1cgEU"
   },
   "source": [
    "## The required libraries loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UVm3TtssKpFb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3b7YGnsXdfX5"
   },
   "source": [
    "### Data retrieved and peep at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "hZhLD31XIf89",
    "outputId": "a9f607f1-e001-41df-d597-1456e865b9af"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/patrickcording/02807-comp-tools/master/docker/work/data/transactions.csv')\n",
    "df.head(5) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ck-p4oOYiikh"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBqDqaBzAghR"
   },
   "source": [
    "#### The data is various companies in different countries and the dates unspecified products were sold. \n",
    "#### The data has 20568 rows and 6 columns. We will subsequently check the unusable entries according to each column. \n",
    "#### The obviously large number of rows make manual identification of wrong entries difficult to examine. We will use the tools available to us to examine, evaluate and manupulate the data so that we can transform the data to suit our purpose. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "-OhxJchxjJYb",
    "outputId": "07a5d5ed-633e-4f5d-c768-399fe0797b18"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vlDcINs-DvBX"
   },
   "source": [
    "### The entries in the column 'part' appears to be nominal in nature. We have therefore decided to simply remove any null entry by rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Z4qwVP63ftj"
   },
   "outputs": [],
   "source": [
    "df.dropna(subset= ['part'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "uFAlNOcj4KSb",
    "outputId": "fcdc02a8-9de9-475b-f9e9-498022c69516"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5oDyXOf3EhID"
   },
   "source": [
    "### It can be seen that 'part' column no longer has null entries. We now move our attention to the column country. \n",
    "\n",
    "## We turn our attention to the 'company' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NjsjxoCHEP83"
   },
   "outputs": [],
   "source": [
    "df1 = df['company'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "colab_type": "code",
    "id": "5pcDqSrL49T3",
    "outputId": "9e206890-f448-4300-e651-17feb685954b"
   },
   "outputs": [],
   "source": [
    "df1.sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "egM02lZBhHhP"
   },
   "source": [
    "#### From the output above, we have do some manupulation by replacing companies with almost equal names with the likeliest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "id": "sEOlTTsKSOk1",
    "outputId": "7a21b327-af3a-4990-dab7-a800db42ee9f"
   },
   "outputs": [],
   "source": [
    "df['company']=df['company'].str.replace('Laj0','Lajo')\n",
    "df['company']=df['company'].str.replace('Ntagz','Ntags')\n",
    "df['company']=df['company'].str.replace('Thoughtmixz','Thoughtmix')\n",
    "df['company']=df['company'].str.replace('Zooxo.','Zooxo')\n",
    "df1 = df['company'].value_counts(dropna = False)\n",
    "df1.sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5IZUnSgNwTSa"
   },
   "source": [
    "#### From the above information, we can deduce that companies '-', 'a', and 'aa' may represent given companies in their own right but we in no way able to know that. We can do further checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "colab_type": "code",
    "id": "gUCJBICe49ye",
    "outputId": "0cd5f563-16ac-4aa1-d73b-052bc8ce2509"
   },
   "outputs": [],
   "source": [
    "company_aa = df[df['company'] == 'aa']\n",
    "company_aa\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "colab_type": "code",
    "id": "PG6XvG4En7WX",
    "outputId": "a69b726a-a18c-441f-9c44-302ef8bd79c2"
   },
   "outputs": [],
   "source": [
    "company_a = df[df['company'] == ' a'] \n",
    "company_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "colab_type": "code",
    "id": "AZdd5vMJ4zEN",
    "outputId": "1457b554-c46b-4438-aecb-0fde7a90ebe8"
   },
   "outputs": [],
   "source": [
    "companydash = df[df['company'] == ' -']\n",
    "companydash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PXCxUmDb4zeR"
   },
   "outputs": [],
   "source": [
    "weird = pd.concat([company_aa, company_a, companydash])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "EquB5vNg4zzI",
    "outputId": "232b6985-540b-4ed7-bd49-e8fafb0a3c4d"
   },
   "outputs": [],
   "source": [
    "pd.merge(df, weird)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zDuelKnxhQYF"
   },
   "source": [
    "#### Now, what we can do is that we look at the all the companies who's city is New York, and we find the the only possible company is 'Wordify'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "pFlwkLcQtWSH",
    "outputId": "6b776cee-fea8-4a0e-a4e0-dc6adfb7f977"
   },
   "outputs": [],
   "source": [
    "df1=df[df.city =='New York']\n",
    "df1.company.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9fK0MP-2REJ"
   },
   "outputs": [],
   "source": [
    "df['company']=df['company'].str.replace(' a','Wordify')\n",
    "df['company']=df['company'].str.replace('aa','Wordify')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1zFmTSJEhvYH"
   },
   "source": [
    "#### Do the same approach for the Boston:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "5dBJANTLtgBw",
    "outputId": "b3be9f91-4b18-40a0-81c2-bd24300c046e"
   },
   "outputs": [],
   "source": [
    "df1 = df[df.city == 'Boston']\n",
    "df1.company.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "colab_type": "code",
    "id": "UR_z7Ul_h0t2",
    "outputId": "e615e79b-2f59-4891-d935-a18de81f979c"
   },
   "outputs": [],
   "source": [
    "df['company']=df['company'].str.replace(' -','Zoonder')\n",
    "df1 = df['company'].value_counts(dropna = False)\n",
    "df1.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4i-KH35aqboX"
   },
   "source": [
    "#### Now, the company part is almost cleaned and is in the usable format, let's move and have a look on country section: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "colab_type": "code",
    "id": "kAGUqva6qmQC",
    "outputId": "12384677-a62b-48de-df8e-172aab08ac13"
   },
   "outputs": [],
   "source": [
    "df1 = df['country'].value_counts(dropna = False)\n",
    "df1.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mDr4I8RLBhxg"
   },
   "source": [
    "#### It is determined countries have a huge number of null values and to use dropna module, we will significantly reduce the number of observations. Our next tasks are to utilise the tools available to use to reduce the number of null values while we keep the reduction of the number of the observations at the minimum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "prK_V5mZq46S"
   },
   "source": [
    "#### Quickly resolving the obvious ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "1Khq8jo-q4nP",
    "outputId": "fb14c8ee-9336-4655-f69e-e2afa6a584b3"
   },
   "outputs": [],
   "source": [
    "df['country']=df['country'].str.replace('Portugal','TrueCountry')\n",
    "df['country']=df['country'].str.replace('Portuga','Portugal')\n",
    "df['country']=df['country'].str.replace('TrueCountry','Portugal')\n",
    "df['country']=df['country'].str.replace('US','United States')\n",
    "df['country']=df['country'].str.replace('Tyskland','Germany')\n",
    "df['city']=df['city'].str.replace('Amadora\\t','Amadora')\n",
    "df1 = df['country'].value_counts(dropna=False)\n",
    "df1.sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aTyjdpmA5LRL"
   },
   "source": [
    "#### Now, we have about 2000 NaN country names, to figure out them we use the the city column and map the country based on it's corrosponding city names, therefore the condistions and choice help us to solvee this issue using the np.select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hxv09fdn4NjT"
   },
   "outputs": [],
   "source": [
    "def mapcountry(df):\n",
    "  conditions = [\n",
    "    (df['city'] == 'Amadora'),\n",
    "    (df['city'] == 'Annecy'),\n",
    "    (df['city'] == 'Lisbon'),\n",
    "    (df['city'] == 'Porto'),\n",
    "    (df['city'] == 'Barcelona'),\n",
    "    (df['city'] == 'London'),\n",
    "    (df['city'] == 'Düsseldorf'),\n",
    "    (df['city'] == 'Braga'),\n",
    "    (df['city'] == 'New York'),\n",
    "    (df['city'] == 'Athens'),\n",
    "    (df['city'] == 'Aranhas'),\n",
    "    (df['city'] == 'Patras'),\n",
    "    (df['city'] == 'Boston'),\n",
    "    (df['city'] == 'Nanterre'),\n",
    "    (df['city'] == 'Amiens'),\n",
    "    (df['city'] == 'Arnhem'),\n",
    "    (df['city'] == 'Almada'),\n",
    "    (df['city'] == 'Nice'),\n",
    "    (df['city'] == 'Paris'),\n",
    "    (df['city'] == 'Arcueil'),\n",
    "    (df['city'] == 'Heraklion'),\n",
    "    (df['city'] == 'Thessaloniki'),\n",
    "    (df['city'] == 'Niihama'),\n",
    "    (df['city'] == 'Nice'),\n",
    "    (df['city'] == 'Asaka'),\n",
    "    (df['city'] == 'Amsterdam'),\n",
    "    (df['city'] == 'Lisbon'),\n",
    "    (df['city'] == 'Lyon'),\n",
    "    (df['city'] == 'Champagnole'),\n",
    "    (df['city'] == 'Zürich')]\n",
    "  choices = ['Portugal', 'France', 'Portugal','Portugal','Spain',\n",
    "           'United Kingdom','Germany','Portugal','United States',\n",
    "           'Greece','Portugal','Greece','United States','France',\n",
    "           'France','Netherlands','Spain','France','France','France','Greece',\n",
    "           'Greece','Japan','France','Japan','Netherlands','Purtgal',\n",
    "           'France','France','Switzerland']\n",
    "  df['country'] = np.select(conditions, choices, default =df['country']) #'Purtgal'\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZJtS7Pe6mWf"
   },
   "outputs": [],
   "source": [
    "df = mapcountry(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "x7ybNTGcsCna",
    "outputId": "05df1727-93c5-4e71-e2b1-536ee375a433"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A0DzzwRs53Uq"
   },
   "source": [
    "#### Now, we have around the 33 Nan for the city names, yet we have the representative company- again we use the same as previous approcah to get the city based on the company names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eJRR-BMrtxyF"
   },
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (df['company'] == 'Thoughtmix'),\n",
    "    (df['company'] == 'Ntags'),\n",
    "    (df['company'] == 'Brainsphere'),\n",
    "    (df['company'] == 'Shufflebeat'),\n",
    "    (df['company'] == 'Zooxo'),\n",
    "    (df['company'] == 'Yozio'),\n",
    "    (df['company'] == 'Teklist'),\n",
    "    (df['company'] == 'Wordify'),\n",
    "    (df['company'] == 'Zoonder'),\n",
    "    (df['company'] == 'Twitterbeat'),\n",
    "    (df['company'] == 'Kanoodle')]\n",
    "choices = ['Amadora', 'Lisbon', 'Braga','Porto','London',\n",
    "           'Patras','Arnhem','New York','Boston',\n",
    "           'Annecy','Niihama']\n",
    "df['city'] = np.select(conditions, choices, default =df['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "gbU1ZIzTxfZP",
    "outputId": "1f6330ab-5440-4c4a-bb60-5f811cb143ed"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbZRHvag7C7i"
   },
   "source": [
    "#### Now taht we have the city names, we use the countrymap to figure out the country names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0U3HdG7Z7Qc3"
   },
   "outputs": [],
   "source": [
    "df = mapcountry(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "jJfePDu97Tbt",
    "outputId": "85bde68e-7587-487d-b5e8-bb1485e7df74"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jR-71TNn7ZC1"
   },
   "source": [
    "#### Above we can see that we minimum deletion, we only have one Nan in the price- Now we should go to the price column, but we go the date since we need clean date for the price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Ri0ZTe4z6Lg"
   },
   "source": [
    "### Looking at the 'date' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7l4aAZWF7_wx"
   },
   "source": [
    "#### the problem we figured out in converting the date as object column to datetime was the two of the rows had the day 32 on june, so we assumed that it could be the 2 of July, instead of 32 June."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "hC2DMy6hcSht",
    "outputId": "52d41945-2376-4f0f-968a-fdead0f36583"
   },
   "outputs": [],
   "source": [
    "df['date']=df['date'].str.replace('2016-06-32 07:22:28','2016-07-2 07:22:28')\n",
    "df['date']=df['date'].str.replace('2016-06-32 08:08:48','2016-07-2 08:08:48')\n",
    "df['date'] = df['date'].astype('datetime64[ns]')\n",
    "df[3539:3541]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bfo-NsL-8KBd"
   },
   "source": [
    "# Part 2: Enriching the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QUVVLm9S8Z_F"
   },
   "source": [
    "Now, the price column must be modified to have all data on single currency, to do that we assume that:\n",
    "* The rows with Na, void, and - is removed since has no specific information\n",
    "* Assume that the negative sign has been written by mistake, so we make them positive.\n",
    "\n",
    "Then, the cleanfinal_float shows the column with price data in float format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "4HzmOrIQt4C_",
    "outputId": "72a12fe3-a4db-4aa3-c39c-78e6ae50a09c"
   },
   "outputs": [],
   "source": [
    "df.dropna(subset= ['price'], inplace=True)\n",
    "newdf =df[df.price != 'void']\n",
    "newdf =newdf[df.price != '-']\n",
    "newdf =newdf[newdf.price != 'na']\n",
    "newdf['Clean_Price']=newdf['price'].str.replace('€','').str.replace('£','').str.replace('$','').str.replace('¥','').str.replace('-','')\n",
    "newdf['Cleanfinal_float']= newdf.Clean_Price.astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-KOne42j8_XH"
   },
   "source": [
    "#### Here, we make division to the price data so that, in the next section we could use the appropriate api to find the conversation rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "oM3UhkacuGuB",
    "outputId": "9ee0b514-aa9b-416f-99e3-458ada8a6ba6"
   },
   "outputs": [],
   "source": [
    "df_pond=newdf[newdf.price.str.contains('£')]\n",
    "df_pond = df_pond.reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_yen=newdf[newdf.price.str.contains('¥')]\n",
    "df_yen = df_yen.reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_dolar=newdf[newdf.price.str.contains('\\$')]\n",
    "df_dolar = df_dolar.reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_euro=newdf[newdf.price.str.contains('€')]\n",
    "df_euro = df_euro.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n9UEw4Nl9SaF"
   },
   "source": [
    "#### The below function find the rate of change for aother currencies at each day (unique days), and save them in the new column named conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1EIK-OMuNUm"
   },
   "outputs": [],
   "source": [
    "def apiconversion(currency, df):\n",
    "    df.loc[:, 'Conversion'] = 0\n",
    "    address= 'https://api.exchangeratesapi.io/YY-MM-DD?symbols=CURRENCY'\n",
    "    XTime = address.replace('CURRENCY',currency)\n",
    "    saveddate = '111111'\n",
    "    for index in range(len(df)):\n",
    "        YY = df.date.iloc[index].year\n",
    "        MM = df.date.iloc[index].month\n",
    "        DD = df.date.iloc[index].day\n",
    "        X_YY=XTime.replace('YY',str(YY))\n",
    "        X_YY_MM = X_YY.replace('MM',str(MM))\n",
    "        X_YY_MM_DD = X_YY_MM.replace('DD',str(DD))\n",
    "        date = str(YY) + str(MM) + str (DD)\n",
    "        if date == saveddate:\n",
    "            df.loc[index,'Conversion']=savedrate\n",
    "        else:\n",
    "            saveddate= str(YY) + str(MM) + str (DD)\n",
    "            r_s= requests.get(X_YY_MM_DD)\n",
    "            json_response=r_s.json()\n",
    "            data_ratio=json_response\n",
    "            savedrate=data_ratio['rates'][currency]\n",
    "            df.loc[index,'Conversion']=savedrate\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YVReow52uDJW"
   },
   "outputs": [],
   "source": [
    "df_pond_conversion=apiconversion('GBP',df_pond)\n",
    "df_dolar_conversion=apiconversion('USD',df_dolar)\n",
    "df_yen_conversion=apiconversion('JPY',df_yen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bEnDu_WJ9jvk"
   },
   "source": [
    "#### Dividing the the price in another currencie to the rate of change to have one unique final currency, Euro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "23jDBaTeuZfh"
   },
   "outputs": [],
   "source": [
    "df_dolar_conversion['Price_euro'] = df_dolar_conversion['Cleanfinal_float']/df_dolar_conversion['Conversion']\n",
    "df_pond_conversion['Price_euro'] = df_pond_conversion['Cleanfinal_float']/df_pond_conversion['Conversion']\n",
    "df_yen_conversion['Price_euro'] = df_yen_conversion['Cleanfinal_float']/df_yen_conversion['Conversion']\n",
    "df_euro['Price_euro'] = df_euro['Cleanfinal_float']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fjdfVJmLu4Wp"
   },
   "outputs": [],
   "source": [
    "DF_euro = df_euro[['part','company','country','city','price','date','Price_euro']]\n",
    "DF_pond = df_pond_conversion[['part','company','country','city','price','date','Price_euro']]\n",
    "DF_dolar = df_dolar_conversion[['part','company','country','city','price','date','Price_euro']]\n",
    "DF_yen = df_yen_conversion[['part','company','country','city','price','date','Price_euro']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gaEYz2JA9zRp"
   },
   "source": [
    "### The DF is the clean data ready for building datatable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Nx2OAehxu6v_",
    "outputId": "b2c574cf-0fd6-4581-ffa1-559c4c4bccd2"
   },
   "outputs": [],
   "source": [
    "DF= DF_euro.append([DF_pond,DF_dolar,DF_yen])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4F2Nl88-4nlt",
    "outputId": "2cf71559-1016-4201-aa2f-1fbb2e0facba"
   },
   "outputs": [],
   "source": [
    "DF['id'] = np.arange(len(DF))\n",
    "DF.set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cp17SyVGz0TI"
   },
   "source": [
    "---\n",
    "## Part 3: Creating a database\n",
    "Storing data in a relational database has the advantages that it is persistent, fast to query, and it will be easier access for other employees at Weyland-Yutani.\n",
    "\n",
    "In this part you should:\n",
    "- Create a database and table(s) for the data\n",
    "- Insert data into the tables\n",
    "\n",
    "You may use SQLite locally to do this. You should argue why you choose to store your data the way you do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPHgY6pa0htL"
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    " \n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    " \n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PkRl3oZG028K"
   },
   "outputs": [],
   "source": [
    "def create_table(conn, create_table_sql):\n",
    "    \"\"\" create a table from the create_table_sql statement\n",
    "    :param conn: Connection object\n",
    "    :param create_table_sql: a CREATE TABLE statement\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(create_table_sql)\n",
    "    except Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZuK0AHJSDGH7"
   },
   "outputs": [],
   "source": [
    "def create_client(conn, client):\n",
    "    \"\"\"\n",
    "    Create a new client into the clients table\n",
    "    :param conn:\n",
    "    :param client:\n",
    "    :return: client id\n",
    "    \"\"\"\n",
    "    sql = ''' INSERT INTO clients(name,country,city)\n",
    "              VALUES(?,?,?) '''\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql, client)\n",
    "    return cur.lastrowid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2yrICwfbC8i"
   },
   "outputs": [],
   "source": [
    "def create_transaction(conn, transaction):\n",
    "    \"\"\"\n",
    "    Create a new transaction into the transactions table\n",
    "    :param conn:\n",
    "    :param transaction:\n",
    "    :return: transaction id\n",
    "    \"\"\"\n",
    "    sql = ''' INSERT INTO transactions(number,product,amount,date,company)\n",
    "              VALUES(?,?,?,?,?) '''\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql, transaction)\n",
    "    return cur.lastrowid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4qn2PcHzLK3S"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NT2y0hnw0Alv"
   },
   "outputs": [],
   "source": [
    "database = r\"C:\\sqlite\\db\\psqlite.db\"\n",
    " \n",
    "sql_create_projects_table = \"\"\" CREATE TABLE IF NOT EXISTS clients (\n",
    "                                        name text NOT NULL PRIMARY KEY,\n",
    "                                        country text,\n",
    "                                        city text\n",
    "                                    ); \"\"\"\n",
    " \n",
    "sql_create_tasks_table = \"\"\"CREATE TABLE IF NOT EXISTS transactions (\n",
    "                                    number text PRIMARY KEY,\n",
    "                                    product text,\n",
    "                                    amount double,\n",
    "                                    date date,\n",
    "                                    company text,\n",
    "                                    FOREIGN KEY (company) REFERENCES clients (name)\n",
    "                                );\"\"\"\n",
    " \n",
    "# create a database connection\n",
    "conn = create_connection(database)\n",
    " \n",
    "# create tables\n",
    "if conn is not None:\n",
    "    # create clients table\n",
    "    create_table(conn, sql_create_projects_table)\n",
    " \n",
    "    # create transactions table\n",
    "    create_table(conn, sql_create_tasks_table)\n",
    "else:\n",
    "    print(\"Error! cannot create the database connection.\")\n",
    "       \n",
    "\n",
    "#Now lets insert the data in our tables\n",
    "#First we start inserting the clients\n",
    "# We get a unique row for every company to fill the companies table\n",
    "df_company=DF.drop_duplicates('company')\n",
    "for index,row in df_company.iterrows():\n",
    "    client_command=(row['company'],row['country'],row['city'])\n",
    "    client_id = create_client(conn, client_command)\n",
    "\n",
    "      \n",
    "#Now we insert the transactions\n",
    "for index,row in DF.iterrows():\n",
    "    transaction_command=(row['id'],row['part'],row['Price_euro'],row['date'].strftime('%Y-%m-%d'),row['company'])\n",
    "    transaction_id = create_transaction(conn, transaction_command)\n",
    "    \n",
    "# Save (commit) the changes\n",
    "conn.commit()\n",
    "\n",
    "# We can also close the connection if we are done with it.\n",
    "# Just be sure any changes have been committed or they will be lost.\n",
    "conn.close()\n",
    "#     cur = conn.cursor()\n",
    "#     cur.execute(\"SELECT * FROM clients\")\n",
    " \n",
    "#     rows = cur.fetchall()\n",
    " \n",
    "#     for row in rows:\n",
    "#         print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GVczcEzI5O9x",
    "outputId": "f95aad0b-a523-4323-a0b6-59f294fd9e3e"
   },
   "outputs": [],
   "source": [
    "database = r\"C:\\sqlite\\db\\psqlite.db\"\n",
    "conn = create_connection(database)\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT * FROM transactions\")\n",
    " \n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "  print(row)\n",
    "  \n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yN8pZkD1J2iQ"
   },
   "source": [
    "---\n",
    "## Part 4: Analyzing the data\n",
    "You are now ready to analyze the data. Your goal is to gain some actionable business insights to present to your boss. \n",
    "\n",
    "In this part, you should ask some questions and try to answer them based on the data. You should write SQL queries to retrieve the data. For each question, you should state why it is relevant and what you expect to find.\n",
    "\n",
    "To get you started, you should prepare answers to the following questions. You should add more questions.\n",
    "#### Who are the most profitable clients?\n",
    "Knowing which clients that generate the most revenue for the company will assist your boss in distributing customer service ressources.\n",
    "\n",
    "#### Are there any clients for which profit is declining?\n",
    "Declining profit from a specific client may indicate that the client is disatisfied with the product. Gaining a new client is often much more work than retaining one. Early warnings about declining profit may help your boss fighting customer churn.\n",
    "\n",
    "\n",
    "Remember, you are taking this to your new boss, so think about how you present the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "colab_type": "code",
    "id": "CviCyUvqVyjS",
    "outputId": "98ad6aa6-1120-42cc-8c6a-67065571962a"
   },
   "outputs": [],
   "source": [
    "database = r\"C:\\sqlite\\db\\psqlite.db\"\n",
    "conn = create_connection(database)\n",
    "#Who are the most profitable clients?\n",
    "#Lets short the clients by amount desc\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT * FROM (SELECT company, SUM(amount) AS amount FROM transactions GROUP BY company) ORDER BY amount DESC\")\n",
    " \n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "  print(row)\n",
    "print(len(rows))\n",
    "\n",
    "  \n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgm2ddxgJ5Gs"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from dateutil import parser\n",
    "from matplotlib import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "yM6g4wxMJ6qu",
    "outputId": "183fc73a-7cb9-4d7d-ae10-b00fc5e07bf3"
   },
   "outputs": [],
   "source": [
    "database = r\"C:\\sqlite\\db\\psqlite.db\"\n",
    "conn = create_connection(database)\n",
    "\n",
    "#Are there any clients for which profit is declining?\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT month, amount FROM (SELECT strftime('%m', date) as month, amount FROM transactions WHERE company='Tagtune' ORDER BY date ASC) GROUP BY month\")\n",
    " \n",
    "dates = []\n",
    "values = []\n",
    "\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "  #print(row)\n",
    "  dates.append(parser.parse(row[0]))\n",
    "  values.append(row[1])\n",
    "\n",
    "plt.plot_date(dates,values,'-')\n",
    "plt.show()\n",
    "\n",
    "  \n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uPdOB2EdJ_Dq"
   },
   "source": [
    "---\n",
    "## Part 5: Performance\n",
    "Your boss is very impressed with what you have achieved in less than two weeks, and he would like to take your idea of storing the customer and sales data in a relational database to production. However, John is concerned that the solution will not scale. His experience is telling him that you will see many occurrences of the following queries.\n",
    "\n",
    "- Show all sales to company X between time $t_1$ and time $t_2$\n",
    "- Show the latest X sales in the database\n",
    "- Show total sales per company per day\n",
    "\n",
    "Show that Johns concern is not justified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "ZJRWxlepKCVb",
    "outputId": "2be2584a-b35a-4090-e8ed-549beacb3594"
   },
   "outputs": [],
   "source": [
    "database = r\"C:\\sqlite\\db\\psqlite.db\"\n",
    "conn = create_connection(database)\n",
    "\n",
    "#Show all sales to company X between time  t1  and time  t2\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT * FROM transactions WHERE company='Yozio' AND date>='2018-12-23' AND date<='2018-12-26'\")\n",
    " \n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "  print(row)\n",
    "print(len(rows))\n",
    "\n",
    "  \n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "LtpPW38rKGdd",
    "outputId": "e639b34f-5dda-4826-ca05-9ad0db19633a"
   },
   "outputs": [],
   "source": [
    "database = r\"C:\\sqlite\\db\\psqlite.db\"\n",
    "conn = create_connection(database)\n",
    "\n",
    "\n",
    "#Show the latest X sales in the database\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT * FROM transactions ORDER BY date DESC LIMIT 10\")\n",
    " \n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "  print(row)\n",
    "print(len(rows))\n",
    "  \n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "27jJ20_PKII-",
    "outputId": "d9067a8e-82e8-4f50-9b35-83ca9d7ff15e"
   },
   "outputs": [],
   "source": [
    "database = r\"C:\\sqlite\\db\\psqlite.db\"\n",
    "conn = create_connection(database)\n",
    "\n",
    "#Show total sales per company per day\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT company,DATE(date), SUM(amount) FROM transactions GROUP BY company,DATE(date)\")\n",
    "\n",
    "  \n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "  print(row)\n",
    "print(len(rows))\n",
    "\n",
    "  \n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DcoNb94pS2Zs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
